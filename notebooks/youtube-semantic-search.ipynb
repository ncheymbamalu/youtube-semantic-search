{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[00mLICENSE\u001b[0m\n",
      "├── \u001b[00mMakefile\u001b[0m\n",
      "├── \u001b[00mREADME.md\u001b[0m\n",
      "├── \u001b[01;34martifacts\u001b[0m\n",
      "│   └── \u001b[01;34membedding_model\u001b[0m\n",
      "│       ├── \u001b[01;34m1_Pooling\u001b[0m\n",
      "│       │   └── \u001b[00mconfig.json\u001b[0m\n",
      "│       ├── \u001b[00mREADME.md\u001b[0m\n",
      "│       ├── \u001b[00mconfig.json\u001b[0m\n",
      "│       ├── \u001b[00mconfig_sentence_transformers.json\u001b[0m\n",
      "│       ├── \u001b[00mmodel.safetensors\u001b[0m\n",
      "│       ├── \u001b[00mmodules.json\u001b[0m\n",
      "│       ├── \u001b[00msentence_bert_config.json\u001b[0m\n",
      "│       ├── \u001b[00mspecial_tokens_map.json\u001b[0m\n",
      "│       ├── \u001b[00mtokenizer.json\u001b[0m\n",
      "│       ├── \u001b[00mtokenizer_config.json\u001b[0m\n",
      "│       └── \u001b[00mvocab.txt\u001b[0m\n",
      "├── \u001b[00mconfig.yaml\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "│   └── \u001b[00myoutube_transcripts.parquet\u001b[0m\n",
      "├── \u001b[00mdata.dvc\u001b[0m\n",
      "├── \u001b[01;34mdocker\u001b[0m\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\n",
      "│   └── \u001b[00myoutube-semantic-search.ipynb\u001b[0m\n",
      "├── \u001b[00mpoetry.lock\u001b[0m\n",
      "├── \u001b[00mpyproject.toml\u001b[0m\n",
      "└── \u001b[01;34msrc\u001b[0m\n",
      "    ├── \u001b[00m__init__.py\u001b[0m\n",
      "    ├── \u001b[00mapp.py\u001b[0m\n",
      "    ├── \u001b[00metl.py\u001b[0m\n",
      "    ├── \u001b[00mfrontend.py\u001b[0m\n",
      "    ├── \u001b[00mlogger.py\u001b[0m\n",
      "    ├── \u001b[00mpaths.py\u001b[0m\n",
      "    ├── \u001b[00msemantic_search.py\u001b[0m\n",
      "    └── \u001b[00mutils.py\u001b[0m\n",
      "\n",
      "8 directories, 28 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Dependencies`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from pathlib import PosixPath\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.paths import PathConfig, load_config\n",
    "from src.utils import embed_transcripts, transcribe_videos\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polars.config.Config at 0x103b39ba0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the Pandas display options\n",
    "pd.set_option(\"display.max_rows\", 100) # max number of rows to display\n",
    "pd.set_option(\"display.max_columns\", None) # max number of columns to display\n",
    "\n",
    "# set the Polars display options\n",
    "pl.Config(\n",
    "    tbl_rows=10, # max number of rows to display\n",
    "    tbl_cols=100, # max number of columns to display\n",
    "    tbl_width_chars=1000, # max table width, in characters\n",
    "    fmt_str_lengths=50, # max number of characters to display for a pl.Utf8 (str) dtype column\n",
    "    fmt_table_cell_list_len=20 # max number of items to display for a pl.List dtype column\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`extract-transform-load`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the YouTube channel IDs\n",
    "youtube_channel_ids: list[str] = load_config().get(\"youtube_channel_ids\")\n",
    "youtube_channel_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of pl.LazyFrames, one per YouTube channel ID\n",
    "lfs: list[pl.LazyFrame] = Parallel(n_jobs=-1)(\n",
    "    delayed(transcribe_videos)(channel_id) for channel_id in tqdm(youtube_channel_ids)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertically concatenate the list of pl.LazyFrames into a single pl.DataFrame\n",
    "df: pl.DataFrame = (\n",
    "    pl.concat(lfs, how=\"vertical\")\n",
    "    .unique(subset=\"video_id\")\n",
    "    .sort(by=\"creation_date\")\n",
    "    .collect()\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [**`Hugging Face Embedding Models Leaderboard`**](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "\n",
    "- [**`15 Best Open Source Text Embedding Models`**](https://www.graft.com/blog/open-source-text-embedding-models#15-open-source-text-embedding-models-updated-april-2024)\n",
    "\n",
    "- [**`Alibaba-NLP/gte-large-en-v1.5 Embedding Model`**](https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the embedding model from Hugging Face\n",
    "model_id: str = load_config().get(\"embedding_model_id\")\n",
    "embedding_model: SentenceTransformer = SentenceTransformer(model_id, trust_remote_code=True)\n",
    "embedding_model, embedding_model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embedding model locally to ~/artifacts/embedding_model/\n",
    "artifacts_dir: PosixPath = PathConfig.ARTIFACTS_DIR\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "embedding_model.save(str(artifacts_dir / \"embedding_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create serialized embeddings for the video transcripts, and ...\n",
    "# write the resulting pl.DataFrame to ~/data/youtube_transcripts.parquet\n",
    "(\n",
    "    df\n",
    "    .pipe(embed_transcripts, embedding_model)\n",
    "    .with_columns(pl.col(\"creation_date\").str.to_datetime())\n",
    "    .write_parquet(PathConfig.PROCESSED_DATA_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_357, 5)\n",
      "┌─────────────┬─────────────────────┬─────────────────────────────────────────────────────┬─────────────────────────────────────────────────────┬─────────────────────────────────────────────────────┐\n",
      "│ video_id    ┆ creation_date       ┆ title                                               ┆ transcript                                          ┆ embedding                                           │\n",
      "│ ---         ┆ ---                 ┆ ---                                                 ┆ ---                                                 ┆ ---                                                 │\n",
      "│ str         ┆ datetime[μs]        ┆ str                                                 ┆ str                                                 ┆ binary                                              │\n",
      "╞═════════════╪═════════════════════╪═════════════════════════════════════════════════════╪═════════════════════════════════════════════════════╪═════════════════════════════════════════════════════╡\n",
      "│ wYPUhge9w5c ┆ 2018-12-23 01:38:06 ┆ Linear Regression: A friendly introduction          ┆ hi I'm Louis Serrano and this is a friendly introd… ┆ b\"Z\\xff\\xa1\\xbe\\xd8g\\x8d\\xbd\\xe7\\xc9H\\xbf\\xb8\\xd6\\… │\n",
      "│ jbluHIgBmBo ┆ 2019-01-01 20:08:19 ┆ Logistic Regression and the Perceptron Algorithm: … ┆ hi I'm Louis serrano and this is a friendly introd… ┆ b\"\\x9a\\xe2\\x0d>\\xac\\xb5\\xff>6r\\xbd=\\x0a\\xf8\\xd6=5\\… │\n",
      "│ jbluHIgBmBo ┆ 2019-01-01 20:08:19 ┆ Logistic Regression and the Perceptron Algorithm: … ┆ hi I'm Louis serrano and this is a friendly introd… ┆ b\"\\x1eT;?f\\x08\\x04?<\\xa6\\xa6><f\\x07>:\\x04%>\\xb4\\xb… │\n",
      "│ Lpr__X8zuE8 ┆ 2019-01-27 14:19:19 ┆ Support Vector Machines (SVMs): A friendly introdu… ┆ hello my name is luis serrano and this is a friend… ┆ b\"L\\xd0P?\\xc0&F<$\\xcdA=\\xf8\\x88r<\\x82\\x11\\xa3\\xbd\\… │\n",
      "│ QXOkPvFM6NU ┆ 2019-01-28 06:20:05 ┆ Clustering: K-means and Hierarchical                ┆ hello i'm luis serrano and this video is about flu… ┆ b\"\\x85\\xf0\\xe0>fz\\xc7>h\\x94\\x0b\\xbdD\\xd8\\x01\\xbd\\x… │\n",
      "│ …           ┆ …                   ┆ …                                                   ┆ …                                                   ┆ …                                                   │\n",
      "│ 4QHg8Ix8WWQ ┆ 2024-10-17 12:50:12 ┆ Fine-Tuning BERT for Text Classification (Python C… ┆ massive Transformer models like GPT 40 llama and C… ┆ b\"$\\x9c\\x11?\\xe9\\x88\\x8c>\\xcb\\xb8$>\\xf4\\xd0~>(\\xc9… │\n",
      "│ j1QcPSLj7u0 ┆ 2024-10-17 19:00:24 ┆ PGVector: Turn PostgreSQL Into A Vector Database    ┆ what is going on guys welcome back in this video t… ┆ b\"\\x16l\\x12?\\xd8p\\x96\\xbe\\xe1\\xb5J\\xbe\\xe2wL?67\\xe… │\n",
      "│ J0rtcad7vWE ┆ 2024-10-17 20:33:00 ┆ How I made $600,000 freelancing on Upwork.          ┆ [Applause] all right just a quick introduction bef… ┆ b\"\\x9c\\xcbQ\\xbf\\xc7B&?\\xbe\\x1e\\xcf\\xbe\\x80\\x00\\x9a… │\n",
      "│ kzP1sFynhxE ┆ 2024-10-18 10:45:05 ┆ NotebookLM: Its More than AI Podcasts- Your Person… ┆ think smarter not harder we're looking at notebook… ┆ b\"\\xb4\\xa9\\xc6=*\\x19S\\xbf\\x7fJ5>\\xde\\x13\\xb3>\\x01\\… │\n",
      "│ HGTBANm0VY4 ┆ 2024-10-18 16:46:41 ┆ Day-5 | Logging with EFK Stack | Elastic Search, F… ┆ hello everyone my name is abishek and welcome back… ┆ b\"\\xbc\\x0bu\\xbd\\xa03\\x0e>h\\x00\\xfd>\\xc8\\x81U?\\xe1\\… │\n",
      "└─────────────┴─────────────────────┴─────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# read in ~/data/youtube_transcripts.parquet \n",
    "print(pl.read_parquet(PathConfig.PROCESSED_DATA_PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
