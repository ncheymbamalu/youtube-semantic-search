{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[00mLICENSE\u001b[0m\n",
      "├── \u001b[00mMakefile\u001b[0m\n",
      "├── \u001b[00mREADME.md\u001b[0m\n",
      "├── \u001b[00mconfig.yaml\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "│   └── \u001b[00myoutube_transcripts.parquet\u001b[0m\n",
      "├── \u001b[00mdata.dvc\u001b[0m\n",
      "├── \u001b[01;34mdocker\u001b[0m\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\n",
      "│   └── \u001b[00myoutube-semantic-search.ipynb\u001b[0m\n",
      "├── \u001b[00mpoetry.lock\u001b[0m\n",
      "├── \u001b[00mpyproject.toml\u001b[0m\n",
      "└── \u001b[01;34msrc\u001b[0m\n",
      "    ├── \u001b[00m__init__.py\u001b[0m\n",
      "    ├── \u001b[00mapp.py\u001b[0m\n",
      "    ├── \u001b[00metl.py\u001b[0m\n",
      "    ├── \u001b[00mfrontend.py\u001b[0m\n",
      "    ├── \u001b[00mlogger.py\u001b[0m\n",
      "    ├── \u001b[00mpaths.py\u001b[0m\n",
      "    ├── \u001b[00msemantic_search.py\u001b[0m\n",
      "    └── \u001b[00mutils.py\u001b[0m\n",
      "\n",
      "5 directories, 17 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Dependencies`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import PosixPath\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.paths import PathConfig, load_config\n",
    "from src.utils import embed_transcripts, transcribe_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polars.config.Config at 0x17ff89e40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the Pandas display options\n",
    "pd.set_option(\"display.max_rows\", 100) # max number of rows to display\n",
    "pd.set_option(\"display.max_columns\", None) # max number of columns to display\n",
    "\n",
    "# set the Polars display options\n",
    "pl.Config(\n",
    "    tbl_rows=10, # max number of rows to display\n",
    "    tbl_cols=100, # max number of columns to display\n",
    "    tbl_width_chars=1000, # max table width, in characters\n",
    "    fmt_str_lengths=50, # max number of characters to display for a pl.Utf8 (str) dtype column\n",
    "    fmt_table_cell_list_len=20 # max number of items to display for a pl.List dtype column\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`extract-transform-load`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the YouTube channel IDs\n",
    "youtube_channel_ids: list[str] = load_config().get(\"youtube_channel_ids\")\n",
    "youtube_channel_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of pl.LazyFrames, one per YouTube channel ID\n",
    "lfs: list[pl.LazyFrame] = Parallel(n_jobs=-1)(\n",
    "    delayed(transcribe_videos)(channel_id) for channel_id in tqdm(youtube_channel_ids)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertically concatenate the list of pl.LazyFrames into a single pl.DataFrame\n",
    "df: pl.DataFrame = (\n",
    "    pl.concat(lfs, how=\"vertical\")\n",
    "    .unique(subset=\"video_id\")\n",
    "    .sort(by=\"creation_date\")\n",
    "    .collect()\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [**`Hugging Face Embedding Models Leaderboard`**](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "\n",
    "- [**`15 Best Open Source Text Embedding Models`**](https://www.graft.com/blog/open-source-text-embedding-models#15-open-source-text-embedding-models-updated-april-2024)\n",
    "\n",
    "- [**`Alibaba-NLP/gte-large-en-v1.5 Embedding Model`**](https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the embedding model from Hugging Face\n",
    "model_id: str = load_config().get(\"embedding_model_id\")\n",
    "embedding_model: SentenceTransformer = SentenceTransformer(model_id, trust_remote_code=True)\n",
    "embedding_model, embedding_model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embedding model locally to ~/artifacts/embedding_model/\n",
    "artifacts_dir: PosixPath = PathConfig.ARTIFACTS_DIR\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "embedding_model.save(str(artifacts_dir / \"embedding_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create serialized embeddings for the video transcripts, and ...\n",
    "# write the resulting pl.DataFrame to ~/data/youtube_transcripts.parquet\n",
    "(\n",
    "    df\n",
    "    .pipe(embed_transcripts, embedding_model)\n",
    "    .with_columns(pl.col(\"creation_date\").str.to_datetime())\n",
    "    .write_parquet(PathConfig.PROCESSED_DATA_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_216, 5)\n",
      "┌─────────────┬─────────────────────┬─────────────────────────────────────────────────────┬─────────────────────────────────────────────────────┬─────────────────────────────────────────────────────┐\n",
      "│ video_id    ┆ creation_date       ┆ title                                               ┆ transcript                                          ┆ embedding                                           │\n",
      "│ ---         ┆ ---                 ┆ ---                                                 ┆ ---                                                 ┆ ---                                                 │\n",
      "│ str         ┆ datetime[μs]        ┆ str                                                 ┆ str                                                 ┆ binary                                              │\n",
      "╞═════════════╪═════════════════════╪═════════════════════════════════════════════════════╪═════════════════════════════════════════════════════╪═════════════════════════════════════════════════════╡\n",
      "│ wYPUhge9w5c ┆ 2018-12-23 01:38:06 ┆ Linear Regression: A friendly introduction          ┆ hi I'm Louis Serrano and this is a friendly introd… ┆ b\"Z\\xff\\xa1\\xbe\\xd8g\\x8d\\xbd\\xe7\\xc9H\\xbf\\xb8\\xd6\\… │\n",
      "│ jbluHIgBmBo ┆ 2019-01-01 20:08:19 ┆ Logistic Regression and the Perceptron Algorithm: … ┆ hi I'm Louis serrano and this is a friendly introd… ┆ b\"\\x9a\\xe2\\x0d>\\xac\\xb5\\xff>6r\\xbd=\\x0a\\xf8\\xd6=5\\… │\n",
      "│ jbluHIgBmBo ┆ 2019-01-01 20:08:19 ┆ Logistic Regression and the Perceptron Algorithm: … ┆ hi I'm Louis serrano and this is a friendly introd… ┆ b\"\\x1eT;?f\\x08\\x04?<\\xa6\\xa6><f\\x07>:\\x04%>\\xb4\\xb… │\n",
      "│ Lpr__X8zuE8 ┆ 2019-01-27 14:19:19 ┆ Support Vector Machines (SVMs): A friendly introdu… ┆ hello my name is luis serrano and this is a friend… ┆ b\"L\\xd0P?\\xc0&F<$\\xcdA=\\xf8\\x88r<\\x82\\x11\\xa3\\xbd\\… │\n",
      "│ QXOkPvFM6NU ┆ 2019-01-28 06:20:05 ┆ Clustering: K-means and Hierarchical                ┆ hello i'm luis serrano and this video is about flu… ┆ b\"\\x85\\xf0\\xe0>fz\\xc7>h\\x94\\x0b\\xbdD\\xd8\\x01\\xbd\\x… │\n",
      "│ …           ┆ …                   ┆ …                                                   ┆ …                                                   ┆ …                                                   │\n",
      "│ 2rLyLe8TOhk ┆ 2024-09-04 16:31:52 ┆ She transitioned to DevOps after 11 years experien… ┆ hello everyone my name is abishek and welcome back… ┆ b\"[\\x8dn\\xbe\\xe9u<\\xbe\\xb5N\\xae\\xbd(\\xc5\\xbd\\xbd~\\… │\n",
      "│ 4hbnc2ewk-U ┆ 2024-09-05 12:38:12 ┆ September Data Engineering Q&A                      ┆ we're going to be doing a Q&A today on data engine… ┆ b\"(\\xb3\\x8a\\xbf\\xfe{\\xa6=g\\xb2\\x1b\\xbf\\x89i\\x1e>B\\… │\n",
      "│ 4hbnc2ewk-U ┆ 2024-09-05 12:38:12 ┆ September Data Engineering Q&A                      ┆ we're going to be doing a Q&A today on data engine… ┆ b\"\\xd7\\xe7\\xa1\\xbf\\x8c\\xc7h\\xbe\\xeb\\xe1\\x02\\xbf=\\x… │\n",
      "│ 4hbnc2ewk-U ┆ 2024-09-05 12:38:12 ┆ September Data Engineering Q&A                      ┆ we're going to be doing a Q&A today on data engine… ┆ b\"H\\x03_\\xbf\\x9b&g\\xbe\\xab\\x1c\\x05\\xbf\\x93h\\xcd\\xb… │\n",
      "│ 5mEmE7pBI1A ┆ 2024-09-05 19:00:03 ┆ Build Your Own News Hub in Python - RSS Feed Aggre… ┆ what is going on guys welcome back in this video t… ┆ b\"\\x83\\x8f\\x05\\xbf\\xa2Q\\x8c>\\xee\\xf0\\xd2>\\xf7\\xb6\"… │\n",
      "└─────────────┴─────────────────────┴─────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# read in ~/data/youtube_transcripts.parquet \n",
    "print(pl.read_parquet(PathConfig.PROCESSED_DATA_PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
